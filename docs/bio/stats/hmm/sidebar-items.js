initSidebarItems({"fn":[["backward",""],["baum_welch","Execute one step of Baum-Welch algorithm to find the maximum likelihood estimate of the parameters of a HMM given a set of observed feature vector and return the estimated initial state distribution (π*), estimated transition matrix (A*), estimated emission probabilities matrix (B*) and end probabilities vector (if the model has declared an end state beforehand). This function doesn’t update the HMM parameters in the model and has been implemented for Discrete Emissions Models only. It return values as `LogProb`."],["forward","Execute the forward algorithm and return the forward probabilites as `LogProb` values and the resulting forward probability."],["viterbi","Execute Viterbi algorithm on the given slice of `Observation` values to get the maximum a posteriori (MAP) probability."]],"mod":[["discrete_emission","Implementation of Hidden Markov Model with emission values from discrete distributions."],["discrete_emission_opt_end","Implementation of Hidden Markov Model with emission values from discrete distributions and an optional explicity end state. This module also implements the `Trainable` trait allowing to be trainned by Baum-Welch algorithm."],["errors","Error definitions for the `hmm` module."],["univariate_continuous_emission","Implementation of Hidden Markov Models with emission values from univariate continuous distributions."]],"struct":[["State","A newtype for HMM states."],["StateIter","Iterate over the states of a `Model`."],["StateTransition","Transition between two states in a `Model`."],["StateTransitionIter","Iterate over all state transitions of a `Model`."]],"trait":[["Model","A trait for Hidden Markov Models (HMM) with generic `Observation` type."],["Trainable","A trait for trainning Hidden Markov Models (HMM) with generic `Observation` type using Baum-Welch algorithm."]]});